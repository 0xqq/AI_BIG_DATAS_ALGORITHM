import tensorflow as tf
import input_data
import numpy as np
import matplotlib.pyplot as plt

mnist  =input_data.read_data_sets("Untitled Folder/",one_hot=True)
trainimgs, trainlabels, testimgs, testlabels = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels 
ntrain, ntest, dim, nclasses  = trainimgs.shape[0], testimgs.shape[0], trainimgs.shape[1], trainlabels.shape[1]

diminput  = 28   #我们分解成28*28，原先是长*宽=28*28,但现在的含义是序列*神经元组，也是28*28,所以每个batch输出值是序列个数28
dimhidden = 128  #神经元个数
dimoutput = nclasses
nsteps    = 28   #因为每个样本是28*28特征图，所以我们分解成28个RNN,每次输入是28，序列化是28
weights = {
    'hidden':tf.Variable(tf.random_normal([diminput,dimhidden])),
    'out':tf.Variable(tf.random_normal([dimhidden,dimoutput]))
}
basic = {
    'hidden':tf.Variable(tf.random_normal([dimhidden])),
    'out':tf.Variable(tf.random_normal([dimoutput]))
}

#RNN神经框架:X是输入样本，本质是h*w*batch_size,steps是切分多少组神经元，我们在设置完隐层后再切分
def _RNN(X,W,b,steps,name):
    #格式转化，开始是batchsize(每次迭代5个)*nsteps(28我们分解成28组神经元)*input(28)
    #转为nsteps*batchsize*input
    X = tf.transpose(X,[1,0,2])
    #再reshape成[nsteps*batchsize,input]格式,也就是nsteps*batchsize是这次迭代的总共次数，交给tensorflow设置为-1
    X = tf.reshape(X,[-1,diminput])
    #初始化隐藏层
    H = tf.matmul(X,W['hidden'])+b['hidden']
    #RNN前需要数据预处理,也就是切分,H是个整体的隐层,进入RNN前需要切分.也可以先切分，但这样更麻烦，所以隐层算完后再切分效率高
    Hsplit = tf.split(0,steps,H)
    #RNN操作
    with tf.variable_scope(name) as scope:
        #变量共享,因为每次name都不一样,容易重复变量，所以设定这个避免变量命名冲突,所有变量名都指向同一内存空间。
        scope.reuse_variables()
        #LSTM计算单元-lstm_cell,forget_bias有选择忘记一些信息，1.0是全部都记住，完成第一个后一般会逐渐忘记
        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(dimhidden,forget_bias==1.0)
        #组件RNN神经网络
        LSTM_0,LSTM_S = tf.nn.rnn(lstm_cell,Hsplit,dtype=tf.float32)
    #最终结果,我们用LSTM_0的最后位置的元素，所以是[-1]
    Out = tf.matmul(LSTM_0[-1],W['out'])+b['out']
    return {'X':X,'H':H,'Hsplit':Hsplit,'LSTM_0':LSTM_0,'LSTM_S':LSTM_S,'O':Out}
    
    
    
#下面开始初始化并计算损失函数
learning_state = 0.01
X = tf.placeholder(tf.float32,[None,nsteps,diminput])
Y = tf.placeholder(tf.float32,[None,dimoutput])
#预测值
rnn = _RNN(X,weights,basic,nsteps,'basic')
pre = rnn['O']
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pre))
#优化器
optm = tf.train.GradientDescentOptimizer(learning_state).minimize(loss)
#结果值
score = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pre,1),tf.argmax(Y,1)),tf.float32))

init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
training_epoch = 100
batch_size = 200
steps = 5
for i in range(training_epoch):
    losses = 0.0
    batch_size = int(trainimgs.shape[0]/batch_size)
    for j in range(batch_size):
        batchx,batchy = mnist.train.batch_size(batch_size)
        batchx = batchx.reshape((batch_size,nsteps,diminput))
        feeds = {X:batchx,Y:batchy}
        sess.run(optm,feed_dict=feeds)
        losses+=sess.run(loss,feed_dict=feeds)
    losses = losses/batch_size
    if i%steps==0:
        feed1 = {X:batchx,Y:batchy}
        testimgs = testimgs.reshape((ntest, nsteps, diminput))
        feed2 = {X: testimgs, Y: testlabels, istate: np.zeros((ntest, 2*dimhidden))}
        train_score = sess.run(score,feed_dict = feed1)
        test_score = sess.run(score,feed_dict = feed2)
        print("Epoch : %03d/%03d Loss : %.9f Train_score : %3.f Test_score : %.3f"%(i,training_epoch,losses,train_score,test_score))


