bayes_cv_tuner = BayesSearchCV(
    estimator=lgb.LGBMRegressor(objective='regression', boosting_type='gbdt', subsample=0.6143),
    # colsample_bytree=0.6453, subsample=0.6143
    search_spaces={
        'learning_rate': (0.01, 1.0, 'log-uniform'),
        'num_leaves': (10, 100),
        'max_depth': (0, 50),
        'min_child_samples': (0, 50),
        'max_bin': (100, 1000),
        'subsample_freq': (0, 10),
        'min_child_weight': (0, 10),
        'reg_lambda': (1e-9, 1000, 'log-uniform'),
        'reg_alpha': (1e-9, 1.0, 'log-uniform'),
        'scale_pos_weight': (1e-6, 500, 'log-uniform'),
        'n_estimators': (50, 150),
    },
    scoring='neg_mean_squared_log_error',  # neg_mean_squared_log_error
    cv=KFold(
        n_splits=5,
        shuffle=True,
        random_state=42
    ),
    n_jobs=1,
    n_iter=100,
    verbose=0,
    refit=True,
    random_state=42
)

# Fit the model
result = bayes_cv_tuner.fit(data[features], target, callback=status_print)

pred = bayes_cv_tuner.predict(test[features])
