


import gc
import random
import warnings
import numpy as np
import pandas as pd
import lightgbm as lgb

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn import model_selection
from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D
from sklearn.preprocessing import normalize

random.seed(2018)
warnings.filterwarnings('ignore')


PATH = ''                                       # 存储数据的路径
train = pd.read_csv(PATH + 'train.csv')
X_train = train.drop(["ID", "target"], axis=1)
y_train = np.log1p(train["target"].values)
flist = [x for x in X_train.columns if not x in ['ID','target']]
test = pd.read_csv(PATH + 'test.csv')

num_train_data = len(train)
num_train_feature = train.shape[1]

num_test_data = len(test)
num_test_feature = test.shape[1]

print("训练集的数据量为:{} , 特征数为: {} , 测试集数据量为:{} , 特征数为:{}".format(num_train_data, num_train_feature,
                                                             num_test_data, num_test_feature))

'''
因为是银行业务，所以0就没意义，统计不为0的数据,如果有不为0的数据，我们显示特征，并排序。
'''
# print("训练集不为0的特征数为: {}".format(train.columns[train.isnull().sum() != 0].size))
# if (train.columns[train.isnull().sum() != 0].size):
#     print("训练集不为0的特征为: {}".format(list(train.columns[train.isnull().sum() != 0])))
#     train[train.columns[train.isnull().sum() != 0]].isnull().sum().sort_values(ascending=False)
#
# print("测试集不为0的特征数为: {}".format(test.columns[test.isnull().sum() != 0].size))
# if (test.columns[test.isnull().sum() != 0].size):
#     print("测试集不为0的特征为: {}".format(list(test.columns[test.isnull().sum() != 0])))
#     test[test.columns[test.isnull().sum() != 0]].isnull().sum().sort_values(ascending=False)


X_test = test.drop(["ID"], axis=1)

'''
去除弱特征性，也就是方差/标准差为0的。
'''
colsToRemove = []
for col in X_train.columns:
    if X_train[col].std() == 0:
        colsToRemove.append(col)

X_train.drop(colsToRemove, axis=1, inplace=True)
X_test.drop(colsToRemove, axis=1, inplace=True)

print("方差为0的列为：",colsToRemove)
print("删除方差为0后的维度为: ", X_train.shape, " ", X_test.shape)

columns = X_train.columns

'''
删除线性相同的特征，也就是相同数值的。
'''
# diffcols = []
# for i in range(len(columns) - 1):
#     vals = X_train[columns[i]].values
#     for j in range(i + 1, len(columns)):
#         if np.array_equal(vals, X_train[columns[j]]):
#             diffcols.append(columns[j])
#
# print("线性相同的特征为:", diffcols)
# X_train.drop(diffcols, axis=1, inplace=True)
# X_test.drop(diffcols, axis=1, inplace=True)
X_train.drop(['d60ddde1b', 'acc5b709d', 'f333a5f60', 'f8d75792f', '912836770', 'f333a5f60'],axis = 1,inplace = True)
X_test.drop(['d60ddde1b', 'acc5b709d', 'f333a5f60', 'f8d75792f', '912836770', 'f333a5f60'],axis = 1,inplace = True)

'''
['d60ddde1b', 'acc5b709d', 'f333a5f60', 'f8d75792f', '912836770', 'f333a5f60']
'''
print("删除线性相同特征后的维度为: ", X_train.shape, " ", X_test.shape)

'''
删除相同列
'''
def drop_sparse(train, test):
    flist = [x for x in train.columns if not x in ['ID','target']]
    for f in flist:
        if len(np.unique(train[f]))<2:
            train.drop(f, axis=1, inplace=True)
            test.drop(f, axis=1, inplace=True)
    return train, test

X_train, X_test = drop_sparse(X_train, X_test)
print("删除相同列特征后的维度为: ", X_train.shape, " ", X_test.shape)

'''
因为是稀疏矩阵，我们尝试增加特殊维度，比如和为0的列。
'''
def add_SumZeros(train, test, features):
    flist = [x for x in train.columns if not x in ['ID','target']]
    if 'SumZeros' in features:
        train.insert(1, 'SumZeros', (train[flist] == 0).astype(int).sum(axis=1))
        test.insert(1, 'SumZeros', (test[flist] == 0).astype(int).sum(axis=1))
    flist = [x for x in train.columns if not x in ['ID','target']]

    return train, test

X_train, X_test = add_SumZeros(X_train, X_test, ['SumZeros'])

print("增加和为0的列的维度为: ", X_train.shape, " ", X_test.shape)

'''
相反，尝试增加非0的总数的列。
'''
def add_SumValues(train, test, features):
    flist = [x for x in train.columns if not x in ['ID','target']]
    if 'SumValues' in features:
        train.insert(1, 'SumValues', (train[flist] != 0).astype(int).sum(axis=1))
        test.insert(1, 'SumValues', (test[flist] != 0).astype(int).sum(axis=1))
    flist = [x for x in train.columns if not x in ['ID','target']]

    return train, test

X_train, X_test = add_SumValues(X_train, X_test, ['SumValues'])

print("增加和为非0的列的维度为: ", X_train.shape, " ", X_test.shape)
#
# '''
# K-means聚类
# '''
#
#
#
# flist_kmeans = []
# for ncl in range(2,11):
#     cls = KMeans(n_clusters=ncl)
#     y_pred = cls.fit_predict(X_train[flist])
#     flist_kmeans.append('kmeans_cluster_'+str(ncl))
# print(flist_kmeans)
#
# gc.collect()
# print("Train set size: {}".format(X_train.shape))
# print("Test set size: {}".format(X_test.shape))
#
# flist = [x for x in X_train.columns if not x in ['ID','target']]
#
# '''
# PCA降维
# '''
# n_components = 20
# flist_pca = []
# pca = PCA(n_components=n_components)
# x_train_projected = pca.fit_transform(normalize(X_train[flist], axis=0))
# x_test_projected = pca.transform(normalize(X_test[flist], axis=0))
# for npca in range(0, n_components):
#     X_train.insert(1, 'PCA_'+str(npca+1), x_train_projected[:, npca])
#     X_test.insert(1, 'PCA_'+str(npca+1), x_test_projected[:, npca])
#     flist_pca.append('PCA_'+str(npca+1))
#     print(pca.components_)
#     print(pca.explained_variance_)
#
# print(flist_pca)
#
# gc.collect()
# print("Train set size: {}".format(X_train.shape))
# print("Test set size: {}".format(X_test.shape))
#
# X_train.head(n=10)
#
# X_test.head(n=10)

'''
最后，我们看看综合起来的效果
'''


# def modiData(data):
#     x1 = []
#     x2=[]
#     for i in range(0,len(data+1)):
#         x1.append(data[i][0])
#         x2.append(data[i][1])
#     x1=np.array(x1)
#     x2=np.array(x2)
#     #重塑数据
#     X=np.array(list(zip(x1,x2))).reshape(len(x1),2)
#     return X
#绘制样式
def drawKmodel(XData,t):
    plt.figure(figsize=(10,10))
    colors = ['g','r','y','b']
    markers = ['o','s','d','h']
    kmeans_model = KMeans(n_clusters=t).fit(XData[flist])
    for i,l in enumerate(kmeans_model.labels_):
        plt.plot(XData[i][0],XData[i][1],color=colors[l],marker=markers[l],ls='None')
        plt.title('%s Countries K-Means'%(len(XData)))

n_components = 20
flist_pca = []
pca = PCA(n_components=n_components)
x_train_projected = pca.fit_transform(normalize(X_train[flist], axis=0))

drawKmodel(x_train_projected,4)




'''
在这场比赛中，零点看起来很重要。对具有更多零的数字与行的行进行值的总和可以帮助模型更好地理解趋势。
'''

'''
大家好，

我是骗子的新手。有人可以解释如何添加额外的功能PCA_1..PCA_20和kmeans_cluster_1..kmeans_cluster_10以及各种聚合列有用吗？我理解单独应用PCA和kmeans来解决问题，但在这种情况下，它们作为功能本身添加。

这是解决这些问题的已知技术吗？我们如何知道哪些功能可以添加到哪种问题？
'''

'''
使用PCA，ICA和其他技术减少维度可能会导致信息丢失。通过缩小维度并生成新要素并将其附加到原始数据集，我们会在较低维度中添加更多可能存在的信息。
'''
