前言:
    最开始我用的是传统的构建相似度，提取词性，拼接重要特征，构建特征来做的。但没有取到很好的效果，原因就是这是基于文本，来预测评分的项目，如果只是单纯的
拿文本相似度来开刀，是很难做好的，因为你搜索的物品，跟物品实际属性，描述，标题，存在很大的噪点数据，即使你在提取词性里做了很多噪点处理，也很难精细的求解
出相似度。所以我开始一个新的想法，这个新的想法，是我在之前kaggle的数据挖掘比赛中联想到的，那就是技术算法要还原于人类本身的认知，也就是工业中的业务。
    
一.项目思路与前期处理方法

    基于前言中提到的这个想法，我开始重新整理数据本身，以及这个项目它的目标是什么，业务是什么，如果换做我是客户，我将会如何使用它。
    后来，我发现了如下几个特点，因为因为这个搜索引擎本质是百度搜索，所以我拿咱们平时用的百度来解释下我为什么这样设计。

    先说个前提，这是装潢+家具的项目，所以大部分都是这类词。我们是针对这个业务去设计特征。
     
    1.最后一个词是否相等 (这个方法中文也同样适用。)
    客户在搜索的时候，通常有几种形式，一个是只搜索一个名词，比如，电脑，那么这时候我们去给用户的应该是惠普电脑，联想电脑，华硕电脑这类。所以创建一个
    特征，只统计搜索词这个特征是否等于标题特征的最后一个词，当然，我们需要在函数里设计一个函数，最后往前对其进行比较。一般来说，最后一个词
    如果相等，我们就返回一个+1的整数，提高它的相似度。

    2.相似性度量(这个方法我认为只用在英文中，中文处理不适合这个。)
    搜索中，可能会出现海尔冰箱，北欧风格。这类词，而我们展现的标题，以及产品描述，如果出现相同词汇的越多，我们就提高的相似度。返回+1.
    但如果没有共同出现，我们需要进一步计算它们的相似性度量。 t1 = sum([1 for z in s1 if edit_distance(z, word) < 2]) 调用nltk的edit_distance
    方法。这个函数意思是俩个英文单词越写法越接近，他们相似度量越小。 其他常用相似度：https://www.jb51.net/article/136217.htm
    举例： str1 = 'bad'
           str2 = 'dad'
          print(edit_distance(str1, str2))
    为什么我们使用相似度量，因为我查看了几种常用的文本相似度，再结合本项目数据，发现在英文中，很多相似的品牌，名字拼写差不多，所以才设计一个方法，
    当然如果俩个单词的不同字母超过2，我就会过滤掉。虽然如果相似，那么就把值+0.5 毕竟不是相等，所以+0.5。
    
    3.共同词汇个数(这个方法中文中也可以使用)
    同理上面，这是我们只统计共同出现的特征个数，不考虑相似性度量。我们再构造俩个特征，也是搜索词和产品标题与产品描述，统计词汇相同
    个数，作为一个特征返回，越大说明相似度越高。
    
    4.增加强特征的权重(中文也适合)
    这个方法是我在kaggle比赛中，最后阶段提取构造强特征后，用一些方差，偏差，最大值，不等于0的sum等方法增加强特征的权重，使其最后的线性权重更接近准确。
    这里我同样用在NLP中。具体方法如下：
    在上述中，共同词汇中，我们再根据这个设计一个标题与搜索词共同长度除以搜索词本身长度，这么设计的原因，就是构造强特征的权重列。至于原因我不好解释，
    就跟数据挖掘这中最后构造强特征的最大值，最小值等一样，你可以当做最后线性拟合时，增强强特征性的权重即可，但在设计中，一定要根据真实情景，比如
    这里我是长度除以搜索词自身长度，这样可以比较共同的权重占据用户通常搜索的权重比例。
    
    如果这个比例越大，我们可以得到一个结论，用户搜索比较少的文字时，我们这个模型可以更好地处理，所以在企业中后续的调参，我们可以多设计一些这样的特征
    再根据用户的反馈，去调整我们的模型。
    
    同理，又构造了属性特征，以及上面的属性与搜索词共同特征个数/搜索词长度。 类似这样的方法还有很多，需要大家团队共同设计。
    
二.项目流程。
    上面是我这次项目的核心点，接下来的内容，基本就是生搬硬套了。具体流程如下。
    1.提取词干，再提取词性，处理英文的噪点词。其实都是一个方法：
    s = (" ").join([str(strNum[z]) if z in strNum else z for z in s.split(" ")])  #将里面数字转化为字符串。也就是噪点处理，中文中通常用停止词
    加过滤数字方式适用。
    s = (" ").join([stemmer.stem(z) for z in s.split(" ")])  # 提取词性。
    
    2.特征工程前的数据处理:比如获取相同词个数，比较最后一个词是否相等，比较编辑相似度，构建评估指标函数。
    
    3.删除原始特征，我们创建好自己的衡量相似度计算后，需要将原有特征删除
    
    4.编码处理
    
    5.初始化TF-IDF相似度模型，CounterVector词向量模型
    
    6.初始化管道，初始化XGB模型，进行管道并行处理。
    
    7.模型predict后，过滤掉业务中<1 大于3的评分。 
    
    
    
    
    
