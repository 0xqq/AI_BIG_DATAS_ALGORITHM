原文: https://blog.csdn.net/nsh119/article/details/79360778

所谓语音识别，就是将一段语音信号转换成相对应的文本信息，系统主要包含特征提取、声学模型，语言模型以及字典与解码四大部分，此外为了更有效地提取特征往往还需要对所采集到的声音信号进行滤波、分帧等音频数据预处理工作，将需要分析的音频信号从原始信号中合适地提取出来；特征提取工作将声音信号从时域转换到频域，为声学模型提供合适的特征向量；声学模型中再根据声学特性计算每一个特征向量在声学特征上的得分；而语言模型则根据语言学相关的理论，计算该声音信号对应可能词组序列的概率；最后根据已有的字典，对词组序列进行解码，得到最后可能的文本表示。



预处理：1. 首尾端的静音切除，降低对后续步骤造成的干扰，静音切除的操作一般称为VAD。

              2. 声音分帧，也就是把声音切开成一小段一小段，每小段称为一帧，使用移动窗函数来实现，不是简单的切开，各帧之间一般是有交叠的。

特征提取：主要算法有线性预测倒谱系数（LPCC）和Mel 倒谱系数（MFCC），目的是把每一帧波形变成一个包含声音信息的多维向量；

声学模型（AM）：通过对语音数据进行训练获得，输入是特征向量，输出为音素信息；

字典：字或者词与音素的对应， 简单来说， 中文就是拼音和汉字的对应，英文就是音标与单词的对应；

语言模型（LM）：通过对大量文本信息进行训练，得到单个字或者词相互关联的概率；

解码：就是通过声学模型，字典，语言模型对提取特征后的音频数据进行文字输出；



语音识别流程的举例（只是形象表述，不是真实数据和过程）：

    1. 语音信号：PCM文件等（我是机器人）

    2. 特征提取：提取特征向量[1 2 3 4 56 0 ...]

    3. 声学模型：[1 2 3 4 56 0]-> w o s i j i q i r n

    4. 字典：窝：w o；我：w o； 是：s i； 机：j i； 器：q i； 人：r n；级：j i；忍：r n；

    5. 语言模型：我：0.0786， 是： 0.0546，我是：0.0898，机器：0.0967，机器人：0.6785；

    6. 输出文字：我是机器人；



不正之处，欢迎提出！~~~谢谢
