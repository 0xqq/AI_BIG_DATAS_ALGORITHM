技术解析:
        首先GAN的基本原理我在ReadMe里已经说明，这里不多解释，主要说一些前沿知识。
        
        (1)核心点
        这个项目模块的核心点就是G网络鉴别器与D网络鉴别器的损失值调整。当它俩足够相似时才是比较好的效果。在训练过程中很容易出现梯度爆炸，
        而标准差我们设置太小又容易过拟合，在图像领域很多大神都尝试用过其他方法。另外GAN网络另一个缺点就是很难训练出多种风格的图片。
        在这里有位大神发表过论文进行过实验改进。
        
        (2)存在问题:
        我在这里简单说下他的思路:是利用俩种D网络鉴别器分别去进行鉴别。因为GAN网络在数学上是优化KL和反KL散度的最小差异，遵循遵循最大似然估计原理，   
        寻求模型参数以最大限度地提高训练数据的似然性。简单说就是优化俩种有矛盾的损失值使其无限接近，但实验中我们的生成模型会覆盖原始图片的多种模式，
        这样会生成一些我们不想要的样本。我们在进行优化时因为只能对这一种模式(也就是一种风格的图片)进行生成，而忽略了其他格式。这样就形成了模式崩溃。
        
        (3)解决方法:
        这个原理是位美国大神发表的论文，具体可以看这个:https://yq.aliyun.com/articles/228765
        有点类似强化学习一部分知识。利用俩个鉴别器。鉴别器D1（通过鉴别数据来自于Pdata而不在生成分布PG中获取高分），
        鉴别器D2（相反地，来自于PG而不在Pdata中）和生成器G（尝试欺骗D1、D2两个鉴别器）。作者将这种方法命名为双鉴别器生成对抗网络（D2GAN）
        
        (4)具体解决过程:
        有点类似强化学习的味道:
        假定一个数据空间中的样本x，如果x是数据分布Pdata(第一种风格图)中的，D1(x)获得高分，如果是模式分布PG(第二种风格图)中的，则获得低分。相反地，
        如果x是模式分布PG中的，D2(x)获得高分，如果是数据分布Pdata中的，D2(x)获得低分。与GAN不同的是，得分的表现形式为R+而不是[0,1]中的概率。
        生成器G的角色与GAN中的相似，即从噪声空间中映射数据与真实数据进行合成后欺骗D1和D2两个鉴别器。
        这三个部分都由神经网络参数化而成，其中D1和D2不分享它们的参数。这种方法被称为双鉴别器生成对抗网络（D2GAN）
        
我的项目整体思路:
        step1: 加载数据(python多线程)
        step2: 创建工具类模块:主要是利用scipy.misc.模块进行读取，里面要有中心截取函数，这个函数是仿照google大神写的思路，他的做法就是将图片生成之后
               需要进行中心截取，最后再拼接。另外我们在进行stride的时候也会产生图片泄漏，在merge中用余数方法进行拼接，具体请看代码。
        step3: 构建模型框架的ops方法，也就是卷积，全连接，反卷积,连接,batch正则。这些通用函数。
               batch正则中我们主要设定它的默认参数，以便调整，为了调用方便，在call函数进行返回。
               连接函数是为了连接1*1卷积部分，为了增加深度，1*1卷积是为了特征提取
               卷积层正常写，反卷积别忘了让输入和输出跟卷积相反就可以起到反卷积作用
               全连接层核心是第一个矩阵的第二维度等于第二个矩阵的第一维度
        step4: 构建网络,我们这里不要忘记初始化噪音，真实图片这些变量后，要用histogram构建图形直方图。而后面要merge的地方需要用scaler变成向量
               格式。损失值按照公式写即可。
        step5: 主函数main中配置好参数，运行即可。
  
我遇到的问题:
        step1: 损失函数调用前，一定要tf.summary.scalar，这是转化为标量格式
        step2: 启动run跑优化器前，一定要tf.summary.histogram,这是转化为直方图格式
        step3: 注意共享变量的用法，一定要用reuse=True来改进
        step4: 很多地方我还是不清楚原理，只是知道这些写就能通过，一些地方是tensorflow原理，一些地方是图像处理知识。
        step5: 深度学习很多地方的确可解释性差。
        step6: 多用打印格式检查比断点好，但断点有时也可使用。
        step7: 输入和输出图像大小必须一样
        step8: G网络因为是生成的图，最终不能用tf.summary.histogram,tf.summary.image 来代替。这是输出的一种带协议的缓冲区图像
        step9: merge_all可以合并所有summar,这样可以把之前我们要合并的损失，各种损失图片都合并，但我们这里有俩种，所以不行。
        step10:tf.summary.merge时确保里面都是string类型，所以要转成scaler格式
        step11:注意设计各个层尺寸。
PS:具体还有很多，一些地方我在有注释版本的代码模块中已经总结，这个项目模块很多地方我是采用网上一部分人写法融入到里面，我发现图像这块知识还有很多
欠缺，只是因为我不是主攻这里，日后有时间我再进行详细研究，而多D2GAN以后再进行研究改进。
        
